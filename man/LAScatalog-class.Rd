% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/LAScatalog.r
\docType{class}
\name{LAScatalog-class}
\alias{LAScatalog-class}
\title{An S4 class to represent a set of .las or .laz files}
\description{
A \code{LAScatalog} object is a representation of a set of las/laz files, since a computer cannot load
all the data at once. A \code{LAScatalog} is a simple way to manage the entire dataset by reading only
the file headers. It enables the user to process a large area or to selectively clip data from a
large area without loading the large area itself. A \code{LAScatalog} can be built with the function
\link{catalog} and is formally an extension of \code{SpatialPolygonsDataFrame}. Thus, \strong{it is}
a \code{SpatialPolygonsDataFrame} that contains extra information that enables users to control
 how the catalog is processed (see details).
}
\details{
A \code{LAScatalog} is formally a  \code{SpatialPolygonsDataFrame} extended with 3 new slots that
contain processing options. Each \code{lidR} function that supports a \code{LAScatalog} as
input will respect these processing options when it is relevant (see documentation of each repective
function). Internally, processing a catalog is almost always the same and relies on few steps:
\enumerate{
\item Create a set of clusters. A cluster is the representation of a region of interest.
\item Loop over each cluster (in parallel or not)
\item For each cluster, load the points inside the region of interest in R, run some R functions,
return the expected output.
\item Merge the outputs of the different clusters once they are all processed to build a continuous
output.
}
So basically, a \code{LAScatalog} is a built-in batch process with the specificity that \code{lidR}
does not loop through files but loops seamlessly through clusters that do not not necessarily match
with the files pattern. This way \code{lidR} can process sequentially tiny regions of interest even
if each file may be individually too big to fit in memory. This is also why point cloud indexation
with lax files may significantly speed-up the processing.\cr\cr
It is important to note that buffered datasets (i.e. files that overlap each other) are not natively
supported by \code{lidR}. When encountering such datasets the user should always filter the
overlap if possible. This is possible if the overlapping points are flagged, for example in the
'withheld' field. Otherwise \code{lidR} will not be able to process the dataset correctly.
}
\section{Slots}{

\describe{
\item{\code{processing_options}}{list. A list that contains some settings describing how the catalog will be
processed (see dedicated section).}

\item{\code{clustering_options}}{list. A list that contains some settings describing how the catalog will be
sub-divided into small cluster to be processed (see dedicated section).}

\item{\code{output_options}}{list. A list that contains some settings describing how the catalog will return
the outputs (see dedicated section).}
}}

\section{Processing options}{

The slot \code{@processing_options} contains a \code{list} of options that drives how a the cluster
(the sub-areas that are sequentially processed) are processed.
\itemize{
\item \strong{core}: interger. How many cores are used. Default is 1.
\item \strong{progress}: boolean. Display a progress bar and a chart of progress. Default is TRUE.
\item \strong{stop_early}: boolean. Stop the processsing before the end if an error occur in one of the clusters.
Default is TRUE.
}
}

\section{Clustering options}{

The slot \code{@clustering_options} contains a \code{list} of options that drives how a the cluster
(the sub-areas that are sequentially processed) are made.
\itemize{
\item \strong{by_file}: boolean. The catalog is process sequentially by file. A clsuter is a file. Default is FALSE.
\item \strong{tiling_size}: numeric. The size of the cluster that will be sequentially processeed. A small size
allows for loading few data at a time saving computer memory. A large size allows for loading large
region at a time, the computation is thus ussualy faster but uses much more computer memory. Not relevent
if \code{by_file = TRUE}
\item \strong{buffer}: numeric. Each cluster can be read with an extra buffer around it to ensure there is
no side effect between to independent cluster and that the output is correct and continuous. This
is mandatory for some algorithms. Default is 0.
\item \strong{alignment}: numeric. A vector of size 2 (x and y coordinates, respectively) to align the
clustering pattern. By default the alignment is made along (0,0) meaning the edgeof a virtual tile
will belong on x = 0 and y = 0 and all the the others will be multiples of the tiling size. Not relevent
if \code{by_file = TRUE}
}
}

\section{Output options}{

The slot \code{@output_options} contains a \code{list} of options that drives how a the cluster
(the sub-areas that are sequentially processed) are written (and by written we mean written in files
or written in R memory).

\itemize{
\item \strong{output_files}: string. A complete path to a templated filename without extension (the
algorithm guess it for you). When several files are going to be written a single string is provided
with a template that is automatically fullfiled. For example this names are possible:
\preformatted{
"/home/user/als/normalized/file_{ID}_segmented"
"C:/user/document/als/zone52_{XLEFT}_{YBOTTOM}_confidential"
"C:/user/document/als/{ORIGINALFILNAME}_normalized"
}
And will generate as many files as needed with custom names for each file. The list of allowed
templates is described in the documentation of each function.
\item \strong{drivers}: list. This contains all the drivers requieres to write seamlessly Raster*,
Spatial*, LAS objects. This don't need to be changed if the user is not an advanced user.
}
}

\seealso{
\link[lidR:catalog]{catalog}
}
